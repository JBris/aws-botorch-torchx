{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "507bc0da-4905-4be4-8580-06d366dfdafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"foo\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"bar\"\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = \"ap-southeast-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9dd28292-2e2e-4642-be7e-1c9496c2b1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torchx\n",
    "\n",
    "from torchx import specs\n",
    "from torchx.components import utils\n",
    "\n",
    "\n",
    "def trainer(\n",
    "    log_path: str,\n",
    "    hidden_size_1: int,\n",
    "    hidden_size_2: int,\n",
    "    learning_rate: float,\n",
    "    epochs: int,\n",
    "    dropout: float,\n",
    "    batch_size: int,\n",
    "    trial_idx: int = -1,\n",
    ") -> specs.AppDef:\n",
    "\n",
    "    # define the log path so we can pass it to the TorchX ``AppDef``\n",
    "    if trial_idx >= 0:\n",
    "        log_path = Path(log_path).joinpath(str(trial_idx)).absolute().as_posix()\n",
    "\n",
    "    return utils.python(\n",
    "        # command line arguments to the training script\n",
    "        \"--log_path\",\n",
    "        log_path,\n",
    "        \"--hidden_size_1\",\n",
    "        str(hidden_size_1),\n",
    "        \"--hidden_size_2\",\n",
    "        str(hidden_size_2),\n",
    "        \"--learning_rate\",\n",
    "        str(learning_rate),\n",
    "        \"--epochs\",\n",
    "        str(epochs),\n",
    "        \"--dropout\",\n",
    "        str(dropout),\n",
    "        \"--batch_size\",\n",
    "        str(batch_size),\n",
    "        # other config options\n",
    "        name=\"trainer\",\n",
    "        script=\"/opt/mnist.py\",\n",
    "        image=\"ghcr.io/jbris/torchx-aws-test:1.0.0\",\n",
    "    )\n",
    "\n",
    "import tempfile\n",
    "from ax.runners.torchx import TorchXRunner\n",
    "\n",
    "# Make a temporary dir to log our results into\n",
    "log_dir = tempfile.mkdtemp()\n",
    "\n",
    "scheduler = \"aws_batch\"\n",
    "# scheduler=\"local_cwd\"\n",
    "\n",
    "ax_runner = TorchXRunner(\n",
    "    tracker_base=\"/tmp/\",\n",
    "    component=trainer,\n",
    "    # NOTE: To launch this job on a cluster instead of locally you can\n",
    "    # specify a different scheduler and adjust arguments appropriately.\n",
    "    scheduler=scheduler,\n",
    "    component_const_params={\"log_path\": log_dir},\n",
    "    cfg={\"queue\": \"torchx_queue\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "187da42d-0d11-406d-9df8-053fa8fdc879",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ax.core import (\n",
    "    ChoiceParameter,\n",
    "    ParameterType,\n",
    "    RangeParameter,\n",
    "    SearchSpace,\n",
    ")\n",
    "\n",
    "parameters = [\n",
    "    # NOTE: In a real-world setting, hidden_size_1 and hidden_size_2\n",
    "    # should probably be powers of 2, but in our simple example this\n",
    "    # would mean that ``num_params`` can't take on that many values, which\n",
    "    # in turn makes the Pareto frontier look pretty weird.\n",
    "    RangeParameter(\n",
    "        name=\"hidden_size_1\",\n",
    "        lower=16,\n",
    "        upper=128,\n",
    "        parameter_type=ParameterType.INT,\n",
    "        log_scale=True,\n",
    "    ),\n",
    "    RangeParameter(\n",
    "        name=\"hidden_size_2\",\n",
    "        lower=16,\n",
    "        upper=128,\n",
    "        parameter_type=ParameterType.INT,\n",
    "        log_scale=True,\n",
    "    ),\n",
    "    RangeParameter(\n",
    "        name=\"learning_rate\",\n",
    "        lower=1e-4,\n",
    "        upper=1e-2,\n",
    "        parameter_type=ParameterType.FLOAT,\n",
    "        log_scale=True,\n",
    "    ),\n",
    "    RangeParameter(\n",
    "        name=\"epochs\",\n",
    "        lower=1,\n",
    "        upper=4,\n",
    "        parameter_type=ParameterType.INT,\n",
    "    ),\n",
    "    RangeParameter(\n",
    "        name=\"dropout\",\n",
    "        lower=0.0,\n",
    "        upper=0.5,\n",
    "        parameter_type=ParameterType.FLOAT,\n",
    "    ),\n",
    "    ChoiceParameter(  # NOTE: ``ChoiceParameters`` don't require log-scale\n",
    "        name=\"batch_size\",\n",
    "        values=[32, 64, 128, 256],\n",
    "        parameter_type=ParameterType.INT,\n",
    "        is_ordered=True,\n",
    "        sort_values=True,\n",
    "    ),\n",
    "]\n",
    "\n",
    "search_space = SearchSpace(\n",
    "    parameters=parameters,\n",
    "    # NOTE: In practice, it may make sense to add a constraint\n",
    "    # hidden_size_2 <= hidden_size_1\n",
    "    parameter_constraints=[],\n",
    ")\n",
    "\n",
    "from ax.metrics.tensorboard import TensorboardMetric\n",
    "from tensorboard.backend.event_processing import plugin_event_multiplexer as event_multiplexer\n",
    "\n",
    "class MyTensorboardMetric(TensorboardMetric):\n",
    "\n",
    "    # NOTE: We need to tell the new TensorBoard metric how to get the id /\n",
    "    # file handle for the TensorBoard logs from a trial. In this case\n",
    "    # our convention is to just save a separate file per trial in\n",
    "    # the prespecified log dir.\n",
    "    def _get_event_multiplexer_for_trial(self, trial):\n",
    "        mul = event_multiplexer.EventMultiplexer(max_reload_threads=20)\n",
    "        mul.AddRunsFromDirectory(Path(log_dir).joinpath(str(trial.index)).as_posix(), None)\n",
    "        mul.Reload()\n",
    "    \n",
    "        return mul\n",
    "\n",
    "    # This indicates whether the metric is queryable while the trial is\n",
    "    # still running. We don't use this in the current tutorial, but Ax\n",
    "    # utilizes this to implement trial-level early-stopping functionality.\n",
    "    @classmethod\n",
    "    def is_available_while_running(cls):\n",
    "        return False\n",
    "\n",
    "val_acc = MyTensorboardMetric(\n",
    "    name=\"val_acc\",\n",
    "    tag=\"val_acc\",\n",
    "    lower_is_better=False,\n",
    ")\n",
    "model_num_params = MyTensorboardMetric(\n",
    "    name=\"num_params\",\n",
    "    tag=\"num_params\",\n",
    "    lower_is_better=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b0f3c7f2-dab7-4677-a85b-a3862c141c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 01-07 00:43:40] ax.modelbridge.dispatch_utils: Using Models.BOTORCH_MODULAR since there is at least one ordered parameter and there are no unordered categorical parameters.\n",
      "[INFO 01-07 00:43:40] ax.modelbridge.dispatch_utils: Calculating the number of remaining initialization trials based on num_initialization_trials=None max_initialization_trials=None num_tunable_parameters=6 num_trials=48 use_batch_trials=False\n",
      "[INFO 01-07 00:43:40] ax.modelbridge.dispatch_utils: calculated num_initialization_trials=9\n",
      "[INFO 01-07 00:43:40] ax.modelbridge.dispatch_utils: num_completed_initialization_trials=0 num_remaining_initialization_trials=9\n",
      "[INFO 01-07 00:43:40] ax.modelbridge.dispatch_utils: `verbose`, `disable_progbar`, and `jit_compile` are not yet supported when using `choose_generation_strategy` with ModularBoTorchModel, dropping these arguments.\n",
      "[INFO 01-07 00:43:40] ax.modelbridge.dispatch_utils: Using Bayesian Optimization generation strategy: GenerationStrategy(name='Sobol+BoTorch', steps=[Sobol for 9 trials, BoTorch for subsequent trials]). Iterations after 9 will take longer to generate due to model-fitting.\n",
      "[INFO 01-07 00:43:40] Scheduler: `Scheduler` requires experiment to have immutable search space and optimization config. Setting property immutable_search_space_and_opt_config to `True` on experiment.\n",
      "[INFO 01-07 00:43:40] Scheduler: Fetching data for newly completed trials: [].\n",
      "/home/jbris/.cache/pypoetry/virtualenvs/aws-botorch-torchx-087hCjDl-py3.10/lib/python3.10/site-packages/ax/modelbridge/cross_validation.py:463: UserWarning:\n",
      "\n",
      "Encountered exception in computing model fit quality: RandomModelBridge does not support prediction.\n",
      "\n",
      "[INFO 01-07 00:43:40] Scheduler: Running trials [0]...\n",
      "[INFO 01-07 00:43:43] Scheduler: Fetching data for newly completed trials: [].\n",
      "[INFO 01-07 00:43:43] Scheduler: Waiting for completed trials (for 1 sec, currently running trials: 1).\n",
      "[INFO 01-07 00:43:44] Scheduler: Fetching data for newly completed trials: [].\n",
      "[INFO 01-07 00:43:44] Scheduler: Waiting for completed trials (for 1.5 sec, currently running trials: 1).\n",
      "[INFO 01-07 00:43:46] Scheduler: Fetching data for newly completed trials: [].\n",
      "[INFO 01-07 00:43:46] Scheduler: Waiting for completed trials (for 2 sec, currently running trials: 1).\n",
      "[INFO 01-07 00:43:49] Scheduler: Fetching data for newly completed trials: [].\n",
      "[INFO 01-07 00:43:49] Scheduler: Waiting for completed trials (for 3 sec, currently running trials: 1).\n",
      "[INFO 01-07 00:43:53] Scheduler: Fetching data for newly completed trials: [].\n",
      "[INFO 01-07 00:43:53] Scheduler: Waiting for completed trials (for 5 sec, currently running trials: 1).\n",
      "[INFO 01-07 00:43:59] Scheduler: Fetching data for newly completed trials: [].\n",
      "[INFO 01-07 00:43:59] Scheduler: Waiting for completed trials (for 7 sec, currently running trials: 1).\n",
      "[INFO 01-07 00:44:07] Scheduler: Fetching data for newly completed trials: [].\n",
      "[INFO 01-07 00:44:07] Scheduler: Waiting for completed trials (for 11 sec, currently running trials: 1).\n",
      "[INFO 01-07 00:44:19] Scheduler: Fetching data for newly completed trials: [].\n",
      "[INFO 01-07 00:44:19] Scheduler: Waiting for completed trials (for 17 sec, currently running trials: 1).\n",
      "[INFO 01-07 00:44:37] Scheduler: Fetching data for newly completed trials: [].\n",
      "[INFO 01-07 00:44:37] Scheduler: Waiting for completed trials (for 25 sec, currently running trials: 1).\n",
      "[INFO 01-07 00:45:03] Scheduler: Fetching data for newly completed trials: [].\n",
      "[INFO 01-07 00:45:03] Scheduler: Waiting for completed trials (for 38 sec, currently running trials: 1).\n",
      "[INFO 01-07 00:45:42] Scheduler: Fetching data for newly completed trials: [].\n",
      "[INFO 01-07 00:45:42] Scheduler: Waiting for completed trials (for 57 sec, currently running trials: 1).\n",
      "[INFO 01-07 00:46:41] Scheduler: Fetching data for newly completed trials: [].\n",
      "[INFO 01-07 00:46:41] Scheduler: Waiting for completed trials (for 86 sec, currently running trials: 1).\n",
      "[INFO 01-07 00:48:08] Scheduler: Fetching data for newly completed trials: [].\n",
      "[INFO 01-07 00:48:08] Scheduler: Waiting for completed trials (for 129 sec, currently running trials: 1).\n",
      "[INFO 01-07 00:50:19] Scheduler: Fetching data for newly completed trials: [].\n",
      "[INFO 01-07 00:50:19] Scheduler: Retrieved FAILED trials: [0].\n"
     ]
    },
    {
     "ename": "FailureRateExceededError",
     "evalue": "Failure rate exceeds the tolerated trial failure rate of 0.5 (at least 1 out of first 1 trials failed or were abandoned). Checks are triggered both at the end of a optimization and if at least 5 trials have either failed, or have been abandoned, potentially automatically due to issues with the trial.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailureRateExceededError\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 47\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01max\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscheduler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Scheduler, SchedulerOptions\n\u001b[1;32m     39\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m Scheduler(\n\u001b[1;32m     40\u001b[0m     experiment\u001b[38;5;241m=\u001b[39mexperiment,\n\u001b[1;32m     41\u001b[0m     generation_strategy\u001b[38;5;241m=\u001b[39mgs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m     ),\n\u001b[1;32m     45\u001b[0m )\n\u001b[0;32m---> 47\u001b[0m \u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_n_trials\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/aws-botorch-torchx-087hCjDl-py3.10/lib/python3.10/site-packages/ax/service/scheduler.py:1025\u001b[0m, in \u001b[0;36mScheduler.run_n_trials\u001b[0;34m(self, max_trials, ignore_global_stopping_strategy, timeout_hours, idle_callback)\u001b[0m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run up to ``max_trials`` trials; will run all ``max_trials`` unless\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;124;03mcompletion criterion is reached. For base ``Scheduler``, completion criterion\u001b[39;00m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;124;03mis reaching total number of trials set in ``SchedulerOptions``, so if that\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;124;03m    3\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoll_and_process_results()\n\u001b[0;32m-> 1025\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_trials_and_yield_results(\n\u001b[1;32m   1026\u001b[0m     max_trials\u001b[38;5;241m=\u001b[39mmax_trials,\n\u001b[1;32m   1027\u001b[0m     ignore_global_stopping_strategy\u001b[38;5;241m=\u001b[39mignore_global_stopping_strategy,\n\u001b[1;32m   1028\u001b[0m     timeout_hours\u001b[38;5;241m=\u001b[39mtimeout_hours,\n\u001b[1;32m   1029\u001b[0m     idle_callback\u001b[38;5;241m=\u001b[39midle_callback,\n\u001b[1;32m   1030\u001b[0m ):\n\u001b[1;32m   1031\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msummarize_final_result()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/aws-botorch-torchx-087hCjDl-py3.10/lib/python3.10/site-packages/ax/service/scheduler.py:965\u001b[0m, in \u001b[0;36mScheduler.run_trials_and_yield_results\u001b[0;34m(self, max_trials, ignore_global_stopping_strategy, timeout_hours, idle_callback)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    963\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m report_results\n\u001b[0;32m--> 965\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_complete_optimization\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_preexisting_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_existing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midle_callback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midle_callback\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/aws-botorch-torchx-087hCjDl-py3.10/lib/python3.10/site-packages/ax/service/scheduler.py:1511\u001b[0m, in \u001b[0;36mScheduler._complete_optimization\u001b[0;34m(self, num_preexisting_trials, idle_callback)\u001b[0m\n\u001b[1;32m   1506\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait_for_completed_trials_and_report_results(\n\u001b[1;32m   1507\u001b[0m     idle_callback\u001b[38;5;241m=\u001b[39midle_callback, force_refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1508\u001b[0m )\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;66;03m# Raise an error if the failure rate exceeds tolerance at the\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;66;03m# end of the optimization.\u001b[39;00m\n\u001b[0;32m-> 1511\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_if_failure_rate_exceeded\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforce_check\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1512\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarn_if_non_terminal_trials()\n\u001b[1;32m   1513\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/aws-botorch-torchx-087hCjDl-py3.10/lib/python3.10/site-packages/ax/service/scheduler.py:824\u001b[0m, in \u001b[0;36mScheduler.error_if_failure_rate_exceeded\u001b[0;34m(self, force_check)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_trials_bad_due_to_err \u001b[38;5;241m>\u001b[39m num_bad_in_scheduler \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    818\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetricFetchE INFO: Sweep aborted due to an exceeded error rate, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    819\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhich was primarily caused by failure to fetch metrics. Please \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck if anything could cause your metrics to be flaky or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbroken.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    822\u001b[0m     )\n\u001b[0;32m--> 824\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_failure_rate_exceeded_error(\n\u001b[1;32m    825\u001b[0m     num_bad_in_scheduler\u001b[38;5;241m=\u001b[39mnum_bad_in_scheduler,\n\u001b[1;32m    826\u001b[0m     num_ran_in_scheduler\u001b[38;5;241m=\u001b[39mnum_ran_in_scheduler,\n\u001b[1;32m    827\u001b[0m )\n",
      "\u001b[0;31mFailureRateExceededError\u001b[0m: Failure rate exceeds the tolerated trial failure rate of 0.5 (at least 1 out of first 1 trials failed or were abandoned). Checks are triggered both at the end of a optimization and if at least 5 trials have either failed, or have been abandoned, potentially automatically due to issues with the trial."
     ]
    }
   ],
   "source": [
    "from ax.core import MultiObjective, Objective, ObjectiveThreshold\n",
    "from ax.core.optimization_config import MultiObjectiveOptimizationConfig\n",
    "\n",
    "\n",
    "opt_config = MultiObjectiveOptimizationConfig(\n",
    "    objective=MultiObjective(\n",
    "        objectives=[\n",
    "            Objective(metric=val_acc, minimize=False),\n",
    "            Objective(metric=model_num_params, minimize=True),\n",
    "        ],\n",
    "    ),\n",
    "    objective_thresholds=[\n",
    "        ObjectiveThreshold(metric=val_acc, bound=0.94, relative=False),\n",
    "        ObjectiveThreshold(metric=model_num_params, bound=80_000, relative=False),\n",
    "    ],\n",
    ")\n",
    "\n",
    "from ax.core import Experiment\n",
    "\n",
    "experiment = Experiment(\n",
    "    name=\"torchx_mnist\",\n",
    "    search_space=search_space,\n",
    "    optimization_config=opt_config,\n",
    "    runner=ax_runner,\n",
    ")\n",
    "\n",
    "total_trials = 48  # total evaluation budget\n",
    "\n",
    "from ax.modelbridge.dispatch_utils import choose_generation_strategy\n",
    "\n",
    "gs = choose_generation_strategy(\n",
    "    search_space=experiment.search_space,\n",
    "    optimization_config=experiment.optimization_config,\n",
    "    num_trials=total_trials,\n",
    "  )\n",
    "\n",
    "from ax.service.scheduler import Scheduler, SchedulerOptions\n",
    "\n",
    "scheduler = Scheduler(\n",
    "    experiment=experiment,\n",
    "    generation_strategy=gs,\n",
    "    options=SchedulerOptions(\n",
    "        total_trials=total_trials, max_pending_trials=4\n",
    "    ),\n",
    ")\n",
    "\n",
    "scheduler.run_n_trials(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f0fbd4-27d2-4b75-b260-2c5ca855d228",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ax.service.utils.report_utils import exp_to_df\n",
    "\n",
    "df = exp_to_df(experiment)\n",
    "df.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cee76bd-3648-4e06-986e-b20aef222cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ax.service.utils.report_utils import _pareto_frontier_scatter_2d_plotly\n",
    "\n",
    "_pareto_frontier_scatter_2d_plotly(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2373a9-d416-44c2-abdd-02099c81398e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ax.modelbridge.cross_validation import compute_diagnostics, cross_validate\n",
    "from ax.plot.diagnostic import interact_cross_validation_plotly\n",
    "from ax.utils.notebook.plotting import init_notebook_plotting, render\n",
    "\n",
    "cv = cross_validate(model=gs.model)  # The surrogate model is stored on the ``GenerationStrategy``\n",
    "compute_diagnostics(cv)\n",
    "\n",
    "interact_cross_validation_plotly(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5356736-da2f-4ae8-9ea8-98f657e638e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6e95ac-ce9e-46ba-bec2-ec054e05e6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ax.plot.contour import interact_contour_plotly\n",
    "\n",
    "interact_contour_plotly(model=gs.model, metric_name=\"val_acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c51195-b948-464e-ad28-4602446bd92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_contour_plotly(model=gs.model, metric_name=\"num_params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebaf89b-4c39-4e77-ba44-df05eeab9e03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
